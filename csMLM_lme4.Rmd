---
title: "csMLM lme4"
author: "Will Sheppard"
date: "2023-09-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

THe aim of this script is to get the best fitting MLM for the contrast sensitivity data by means of AIC comparison, whereby we will compare 3 distributions: Gamma, Gaussian and Inverse Gausia using the lme4 package. The lmer funciton will be used for the Gaussian distributions and the glmer function will be used for the Gamma and inverse gausian distributions.

fixed parameters: visual condition and age
random parameters: Participant id and researcher

Reearcher will be entered as a random effect as each researher used a different laptop, so this may effect the overall outcome and we are interested in modelling this variability but are not strictly interested in this effect with regards our research question.

```{r packages}
library(tidyverse)


```

```{r read data}

pplist <- read.csv("../cleanData/pplist.csv")%>%
  dplyr::select(-X) %>%
  rename(id = x)

pps <- as.list(pplist$id)

cs <- read.csv("../cleanData/csThresh.csv")%>%
  filter(id %in% pps)

demo <- read.csv("../studentData/studentDemographicsWideEdit.csv")%>%
  filter(Participant.Private.ID %in% pps)


```

To identify the reserarcher, we need to identify the 3 unique combos of OS and monitor size
```{r researcher id}

resDF <- demo %>%
  dplyr::select(Participant.Private.ID, Participant.OS, Participant.Monitor.Size) 

resDF <- na.omit(resDF)
  
resDF <- resDF %>%
  mutate(pcID = paste(Participant.OS, Participant.Monitor.Size)) %>%
  mutate(resID = case_when(
    pcID == "Windows 10 1536x864" ~ 1,
    pcID == "Windows 10 1280x720" ~ 2,
    pcID == "Mac OS 10.15.7 1440x900" ~ 3
  )) %>%
  dplyr::select(Participant.Private.ID, resID)%>%
  rename(id = Participant.Private.ID)

```

Create a data frame containing participant id and their age
```{r particiapnt age}

age <- demo %>%
  select(Participant.Private.ID, age_in_years) %>%
  rename(id = Participant.Private.ID)

```


now we will join the three data frames on Participant id 
revalue condition so that clear is 0 and blur is 1. the coefficient will down us the 'effect' of blur on va
```{r join df}

csAge <- left_join(cs, age)
d <- left_join(csAge, resDF, by = "id") %>%
  rename(age = age_in_years)%>%
  mutate(condition = case_when(
    condition == 'clear' ~ 0,
    TRUE ~ 1
  ))

d$id <- as.factor(d$id)
d$condition <- as.factor(d$condition)
d$resID <- as.factor(d$resID)

```


```{r packages}
require(lme4)
require(lmerTest)

```

Lets start with the gaussian distribution
```{r gaussian 1}
csFit <- lmer(CS ~ (1|id),
         data = d)
summary(csFit)

```

add visual condition
sig effect of condition
double ceck with anova
sig better fit. retain
```{r gaussian 2}
csCond <- lmer(CS ~ condition + (1|id),
         data = d)
summary(csCond)
anova(csCond, csFit)
```

add age
sig effect of age, double check with anova
sig better fit. retain
```{r gaussian 3}
csAge <- lmer(CS ~ condition + age + (1|id),
         data = d)
summary(csAge)
anova(csAge, csCond)
```

give each researcher their own intercept
sig better fit, retain
```{r gaussian 4}
csRes <- lmer(CS ~ condition + age + (1|resID) + (1|id),
         data = d)
summary(csRes)
anova(csAge, csRes)

csGaussian <- csRes
```

allow slope to vary by condition
topo many random effects for the number of particiapnts. cannot add.
```{r gaussian 5, eval=FALSE}
csCondSlope <- lmer(CS ~ condition + age + (1|resID) + (condition|id),
         data = d)
```

Lets have a look at invesse gaussian
```{r inv gaussian 1}
ingFit <- glmer(CS ~ (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d)
summary(ingFit)

```

add visual condition
sig effect of condition
double ceck with anova
sig better fit. retain
```{r inv gaussian 2}
ingCond <- glmer(CS ~ condition + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d)
summary(ingCond)
anova(ingCond, ingFit)
```

add age
sig effect of age, double check with anova
sig better fit. retain
```{r inv gaussian 3}
d$scaledAge <- scale(d$age)

ingAge <- glmer(CS ~ condition + scaledAge + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(ingAge)
anova(ingAge, ingCond)

```

give each researcher their own intercept
sig better fit, retain
```{r inv gaussian 4}
ingRes <- glmer(CS ~ condition + scaledAge + (1|resID) + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(ingRes)
anova(ingAge, ingRes)

#csGaussian <- csRes
```

```{r check inv gaussian 4}

# https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
# if this value is close to zero we have a sign of singularity, not a problem here ~ 1.16
tt <- getME(ingRes, "theta")
ll <- getME(ingRes, "lower")
min(tt[ll==0])

# chekc gradient calculations - scaled v absolute
derivs1 <- ingRes@optinfo$derivs
sc_grad1 <- with(derivs1,solve(Hessian,gradient))
max(abs(sc_grad1)) # this gradient is tiny ~ .0005. It seems that age is preventing the model converging
max(pmin(abs(sc_grad1),abs(derivs1$gradient))) # comparison of absolute and scaled gradients. tolerance usually 0.001. we are at 0.0005.
# remove age

```

run without age, see it this converges
no sig differnece in fit without age. 
lack of convergence with age increases chance of parameter misestimation
make this final inv. gaussian model
```{r inv gaussian 5}
ingRes2 <- glmer(CS ~ condition + (1|resID) + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(ingRes2)
anova(ingRes2, ingRes)

csInvGauss <- ingRes2
```

give the conditon it's own slope
doesn't converge. Exclude
```{r inv gaussian 6, eval=FALSE}
ingCondSlope <- glmer(CS ~ condition + (1|resID) + (condition|id),
                family = inverse.gaussian(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(ingCondSlope)
anova(ingCondSlope, ingRes2)

#csInvGauss <- ingRes2
```

let's have a look at gamma
```{r gamma 1}
gammaFit <- glmer(CS ~ (1|id),
                family = Gamma(link = "identity"),
         data = d)
summary(gammaFit)

```

add visual condition
sig effect of condition
double ceck with anova
sig better fit. retain
```{r gamma 2}
gammaCond <- glmer(CS ~ condition + (1|id),
                family = Gamma(link = "identity"),
         data = d)
summary(gammaCond)
anova(gammaCond, gammaFit)
```

add age
sig effect of age, double check with anova
sig better fit. retain
```{r gamma 3}
#d$scaledAge <- scale(d$age)

gammaAge <- glmer(CS ~ condition + scaledAge + (1|id),
                family = Gamma(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(gammaAge)
anova(gammaAge, gammaCond)

```

give each researcher their own intercept
sig better fit
# age no longer a sig predictor, remove

```{r gamma 4}
gammaRes <- glmer(CS ~ condition + scaledAge + (1|resID) + (1|id),
                family = Gamma(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(gammaRes)
anova(gammaAge, gammaRes)

#csGaussian <- csRes
```

```{r gamma 5}
require(car)
require(MASS)
require(broom)

gammaCondSlope <- glmer(CS ~ condition + (1|resID) + (condition|id),
                family = Gamma(link = "identity"),
         data = d, 
         control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(gammaCondSlope)
anova(gammaCondSlope, gammaRes)

csGamma <- gammaCondSlope
Confint(csGamma)

lme4::isSingular(csGamma)
lme4::isGLMM(csGamma)
confint(csGamma, method = "boot")
confint.gl(csGamma)
check.conv.grad(csGamma)
ranef(csGamma)
print(csGamma)
vcov(csGamma)
coef(csGamma)


```

```{r model summary table}

require(modelsummary)
require(tibble)
require(flextable)

descriptions <- tibble::tribble(~Description, 
                                "µCS intercept", 
                                "The effect of visual condition on µCS", 
                                "The effect of age on µCS",
                                "The SD of the unique intercepts for each participant",
                                "The SD of the unique intercepts for each researcher",
                                "???",
                                "The SD of the gradient of the slopes of visual condition for each participant",
                                " The correlation of the slope gradient and intercept for each participant",
                                "Number of observations - 2 per participant",
                                "Marginal R^2<br>
                                Variance explained by fixed effects",
                                "Conditional R^2<br>
                                Variance explained by fixed and random effects",
                                "Akaike Information Criterion (AIC)<br> 
                                Considers the trade-off between model fit and model complexity by incorporating the likelihood, number of parameters, and sample size.<br> 
                                AIC = n * ln(SSE/n) + 2 * k",
                                "Bayesian Information Criterion (BIC)<br>
                                Introduces a stronger penalty for model complexity, prioritizing simpler models.<br>
                                BIC = -2 * log(L) + k * log(n)",
                                "How strongly group members correlate with one another.<br>
                                Values < 0.5 = poor reliability<br>
                                0.75 > Values >= 0.5 = moderate reliability<br>
                                0.9 > Values >= 0.75 = good reliability<br>
                                Values >= 0.90 = excellent reliability.",
                                "Square root of the variance of the residuals and indicates the absolute fit of the model to the data.<br>
                                Lower values indicate a bbetter fit."
                                )
attr(descriptions, "position") <- c(2)

notes <- "Table Xva. MLM estimates for the effects of visual condition and age on VA. No p-value is presented for the intercept as the modelled data has been untransformed for the ease of interpretation. See the data and analysis code available at [blah blah] for the transformed data."

modelsummary(list("Gaussian" = csGaussian, "Inverse Gaussian" = csInvGauss, "Gamma" = csGamma), 
             stars = T, 
             title = "CS MLM output",
             estimate = "{estimate} [{conf.low}, {conf.high}]{stars}",
             statistic = "({std.error})",
             shape = term ~ model + statistic, #statistics in separate columns
             coef_rename = c("condition1" = "Visual Condition",
                             "age" = "Age",
                             "SD (Intercept id)" = "SD (Intercept Participant ID)",
                             "SD (Intercept resID)" = "SD (Intercept Researcher ID)",
                             "SD (condition1 id)" = "SD (Slope Visual Condition)"),
             add_columns = descriptions,
             notes = notes,
             output = "csDistTable.html"
             )
```
