---
title: "vaMLM 2"
author: "Will Sheppard"
date: "2023-09-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

THe aim of this script is to get the best fitting MLM for the visual acuity data by means of AIC comparison, whereby we will compare 4 distributions: Normal, Gamma, Gaussian and Inverse Gausia using the lme4 package. The lmer funciton will be used for the normal and Gamma distributions and the glmer function will be used for the Gausian and inverse gausian distributions.

fixed parameters: visual condition and age
random parameters: Participant id and researcher

Reearcher will be entered as a random effect as each researher used a different laptop, so this may effect the overall outcome and we are interested in modelling this variability but are not strictly interested in this effect with regards our research question.

```{r packages}
library(tidyverse)


```

```{r read data}

pplist <- read.csv("../cleanData/pplist.csv")%>%
  dplyr::select(-X) %>%
  rename(id = x)

pps <- as.list(pplist$id)

va <- read.csv("../cleanData/vaThresh.csv")%>% 
  rename(VA = threshold) %>%
  filter(Participant.Private.ID %in% pps)

demo <- read.csv("../studentData/studentDemographicsWideEdit.csv")%>%
  filter(Participant.Private.ID %in% pps)


```


To identify the reserarcher, we need to identify the 3 unique combos of OS and monitor size
```{r researcher id}

resDF <- demo %>%
  dplyr::select(Participant.Private.ID, Participant.OS, Participant.Monitor.Size) 

resDF <- na.omit(resDF)
  
resDF <- resDF %>%
  mutate(pcID = paste(Participant.OS, Participant.Monitor.Size)) %>%
  mutate(resID = case_when(
    pcID == "Windows 10 1536x864" ~ 1,
    pcID == "Windows 10 1280x720" ~ 2,
    pcID == "Mac OS 10.15.7 1440x900" ~ 3
  )) %>%
  dplyr::select(Participant.Private.ID, resID)

```

Create a data frame containing participant id and their age
```{r particiapnt age}

age <- demo %>%
  select(Participant.Private.ID, age_in_years)

```


now we will join the three data frames on Participant id 
revalue condition so that clear is 0 and blur is 1. the coefficient will down us the 'effect' of blur on va
```{r join df}

vaAge <- left_join(va, age)
d <- left_join(vaAge, resDF) %>%
  rename(age = age_in_years)%>%
  mutate(condition = case_when(
    condition == 'clear' ~ 0,
    TRUE ~ 1
  ))%>%
  rename(id = Participant.Private.ID)

d$id <- as.factor(d$id)
d$condition <- as.factor(d$condition)
d$resID <- as.factor(d$resID)
```

```{r gaussian fit 1}
require(lme4)
require(lmerTest)

va <- lmer(VA ~ (1|id),
         data = d)
summary(va)

```

add condition to the model
sig better fit. retain

```{r gaussian fit 2}
vaCond <- lmer(VA ~ condition + (1|id),
         data = d)

anova(vaCond, va)

summary(vaCond)
```


add age to the model
small improvement to fit, retain
```{r gaussian fit 3}

vaAge <- lmer(VA ~ condition + age + (1|id),
         data = d)

anova(vaAge, vaCond)

summary(vaAge)
confint(vaAge, method ="Wald")


```

add random slope to condition
too many random effects for the number of observations 
```{r gaussian fit 4, eval=FALSE}

vaSlope <- lmer(VA ~ condition + age + (condition|id),
         data = d)
```

Worse fit. 
make vaAge into vaGaussian
```{r gaussian fit 5}
vaRes <- lmer(VA ~ condition + age + (1|resID) + (1|id),
         data = d)

anova(vaRes, vaAge)

vaGaussian <- vaAge
```

lets take a look at inverse gaussian
```{r inv g fit 1}
d$VA.t <- d$VA+1

invVa <- glmer(VA.t ~ (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d)
summary(invVa)
```

add condition
sig better fit retain
```{r inv g fit 2}
invCond <- glmer(VA.t ~ condition + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d)
summary(invCond)
anova(invCond, invVa)

vaInv <- invCond

```

let's add age
age is causing a failed convergence, scale age
age is not a sig predictor. do not retain
```{r inv g fit 3, eval=FALSE}
d$age.s <- scale(d$age)

invAge <- glmer(VA.t ~ condition + age.s + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d)
summary(invAge)
```

add random intercept for resID
leads to singularity, try an optimiser
still singular, sd(resID) is approachig xero, probably won't change fit, check with anova
no difference in fit, exclude
```{r inv g fit 4, eval =FALSE}

invRes <- glmer(VA.t ~ condition + (1|resID) + (1|id),
                family = inverse.gaussian(link = "identity"),
         data = d, 
                 glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))
summary(invRes)
anova(invRes, invCond)
```

try random slope of condition
did not converege, try optimiser
still no convergence. make incCond vaInv
```{r inv g fit 5}
invSlope <- glmer(VA.t ~ condition + (condition|id),
                family = inverse.gaussian(link = "identity"), 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000000)),
         data = d)

```

let's try gamma
```{r gamma fit 1}

gammaVa <- glmer(VA.t ~ (1|id),
                family = Gamma(link = "identity"),
         data = d)
summary(gammaVa)
```

let's add condition
sig beter fit, retain
```{r gamma fit 2}
gammaCond <- glmer(VA.t ~ condition + (1|id),
                family = Gamma(link = "identity"),
         data = d)
summary(gammaCond)
anova(gammaCond, gammaVa)

```

let's add age
age causing singularity, rescale age
age is not a sig predictor, do not include
```{r gamma fit 3, eval=FALSE}
d$age.s <- scale(d$age)

gammaAge <- glmer(VA.t ~ condition + age.s + (1|id),
                family = Gamma(link = "identity"),
         data = d)
summary(gammaAge)
```

add random slope for resID
creates singularity, try an optimiser - still singualr, check gradient
gradient approaching 0, check anova, no change in fit predicted
no diff in fit, reject. 
```{r gamma fit 4, eval=FALSE}
gammaRes <- glmer(VA.t ~ condition + (1|resID) + (1|id),
                family = Gamma(link = "identity"),
         data = d,
         glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))

summary(gammaRes)
anova(gammaRes, gammaCond)

```

add a slope for condition
sig better fit, make gammaVa <- gammaSlope
```{r gamma fit 5}
gammaSlope <- glmer(VA.t ~ condition + (condition|id),
                family = Gamma(link = "identity"),
         data = d,
         glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 10000000)))

summary(gammaSlope)
anova(gammaSlope, gammaCond)
vaGamma <- gammaSlope
```

Let's compare the three distributions
```{r model summary table}
require(modelsummary)
require(tibble)
require(flextable)

descriptions <- tibble::tribble(~Description, 
                                "µVA intercept", 
                                "The effect of visual condition on µVA", 
                                "The effect of age on µVA",
                                "The SD of the unique intercepts for each participant",
                                "???",
                                "The SD of the gradient of the slopes of visual condition for each participant",
                                " The correlation of the slope gradient and intercept for each participant",
                                "Number of observations - 2 per participant",
                                "Marginal R^2<br>
                                Variance explained by fixed effects",
                                "Conditional R^2<br>
                                Variance explained by fixed and random effects",
                                "Akaike Information Criterion (AIC)<br> 
                                Considers the trade-off between model fit and model complexity by incorporating the likelihood, number of parameters, and sample size.<br> 
                                AIC = n * ln(SSE/n) + 2 * k",
                                "Bayesian Information Criterion (BIC)<br>
                                Introduces a stronger penalty for model complexity, prioritizing simpler models.<br>
                                BIC = -2 * log(L) + k * log(n)",
                                "How strongly group members correlate with one another.<br>
                                Values < 0.5 = poor reliability<br>
                                0.75 > Values >= 0.5 = moderate reliability<br>
                                0.9 > Values >= 0.75 = good reliability<br>
                                Values >= 0.90 = excellent reliability.",
                                "Square root of the variance of the residuals and indicates the absolute fit of the model to the data.<br>
                                Lower values indicate a bbetter fit."
                                )
attr(descriptions, "position") <- c(2)

notes <- "MLM estimates for the effects of visual condition and age on VA. No p-value is presented for the intercept as the modelled data has been untransformed for the ease of interpretation. See the data and analysis code available at [blah blah] for the transformed data."

modelsummary(list("Gaussian" = vaGaussian, "Inverse Gaussian" = vaInv, "Gamma" = vaGamma),
             stars = T,
             title = "VA MLM output",
             estimate = "{estimate} [{conf.low}, {conf.high}]{stars}",
             statistic = "({std.error})",
             shape = term ~ model + statistic, #statistics in separate columns
             coef_rename = c("condition1" = "Visual Condition",
                             "age" = "Age",
                             "SD (Intercept id)" = "SD (Intercept Participant ID)",
                             "SD (Intercept resID)" = "SD (Intercept Researcher ID)",
                             "SD (condition1 id)" = "SD (Slope Visual Condition)"),
             add_columns = descriptions,
             notes = notes,
             output = "vaDistTable.html"
             )

```